{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# 🔬 DiffLlama vs Llama: Google Colab 实验\n",
        "\n",
        "这个 Notebook 用于在 Google Colab 环境中运行 DiffLlama 与 Llama 在数学推理任务中的噪声鲁棒性对比实验。\n",
        "\n",
        "## 📋 实验概述\n",
        "- **目标**: 对比 DiffLlama-375M 与 Llama-375M 在含噪数学问题上的表现\n",
        "- **数据集**: GSM8K 数学推理数据集及其噪声变体\n",
        "- **评估**: 零样本性能 + 注意力机制分析\n",
        "- **环境**: Google Colab (GPU 推荐)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "## 🚀 第一步：环境设置\n",
        "\n",
        "首先检查运行环境并设置必要的配置。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "check_environment",
        "outputId": "fc3636ae-b502-48c7-80f3-8c06a087c830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🖥️  CUDA available: False\n",
            "⚠️  No GPU detected. Experiment will be slow on CPU.\n"
          ]
        }
      ],
      "source": [
        "# 检查 GPU 可用性\n",
        "import torch\n",
        "print(f\"🖥️  CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"🔧 GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"💾 GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"⚠️  No GPU detected. Experiment will be slow on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clone_repo",
        "outputId": "3f8dc053-13bf-4be3-832e-6e74ed7ef47a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Project files found\n"
          ]
        }
      ],
      "source": [
        "# 如果项目文件不在当前目录，从 Git 仓库克隆\n",
        "# 替换为您的实际仓库地址\n",
        "import os\n",
        "if not os.path.exists('colab/experiment.py'):\n",
        "    print(\"📥 Cloning repository...\")\n",
        "    !git clone https://github.com/github-bowen/DiffLlama-Math-Robustness.git\n",
        "    print(\"📥 Copying files...\")\n",
        "    !cp -r DiffLlama-Math-Robustness/* .\n",
        "    print(\"📥 Removing repository...\")\n",
        "    !rm -rf DiffLlama-Math-Robustness\n",
        "    print(\"📥 Done\")\n",
        "else:\n",
        "    print(\"✅ Project files found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload_section"
      },
      "source": [
        "## 📁 第二步：上传项目文件\n",
        "\n",
        "如果您没有使用 Git 克隆，请手动上传以下文件到 Colab：\n",
        "\n",
        "**必需文件**:\n",
        "- `colab_experiment.py` (主要的 Colab 脚本)\n",
        "- `pre_download_models.py` (模型下载脚本)\n",
        "- `src/` 目录下的所有 Python 文件\n",
        "- `requirements.txt`\n",
        "\n",
        "使用 Colab 的文件上传功能或从 Google Drive 复制文件。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "instructions_section"
      },
      "source": [
        "## 📖 第三步：查看使用说明\n",
        "\n",
        "运行下面的命令查看详细的使用说明和选项。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "show_instructions",
        "outputId": "acd9be1d-4cd1-4027-8214-1584d3a43e9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🎯 GOOGLE COLAB USAGE INSTRUCTIONS\n",
            "\n",
            "1. 📱 Basic Setup (Run once):\n",
            "   !python colab/experiment.py --setup\n",
            "\n",
            "2. 🚀 Quick Test (Recommended first run):\n",
            "   !python colab/experiment.py --mode quick\n",
            "\n",
            "3. 📊 Medium Experiment:\n",
            "   !python colab/experiment.py --mode medium --use-drive\n",
            "\n",
            "4. 🔬 Full Experiment:\n",
            "   !python colab/experiment.py --mode full --use-drive --max-samples 500\n",
            "\n",
            "🔧 Options:\n",
            "   --mode: quick/medium/full\n",
            "   --use-drive: Save models and results to Google Drive\n",
            "   --max-samples: Limit number of evaluation samples\n",
            "   --skip-attention: Skip attention analysis to save time\n",
            "   --help: Show all options\n",
            "\n",
            "💡 Tips:\n",
            "   - Use --use-drive to persist models across sessions\n",
            "   - Start with quick mode to verify everything works\n",
            "   - Monitor GPU memory usage in Colab\n",
            "\n",
            "📁 Results will be saved to:\n",
            "   - Local: /content/results/\n",
            "   - Drive: /content/drive/MyDrive/DiffLlama_Experiment/results/\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# 显示使用说明\n",
        "!python colab/experiment.py --instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_run_section"
      },
      "source": [
        "## 🔧 第四步：初始设置\n",
        "\n",
        "运行初始设置，安装依赖包并配置环境。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq8duQXXpnBa",
        "outputId": "5824dab8-d1af-4c77-c2db-ebbcf514407c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial_setup",
        "outputId": "142da218-3b51-417a-e4f5-1ead00f358ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "🔬 DIFFLAMA VS LLAMA - GOOGLE COLAB EXPERIMENT\n",
            "================================================================================\n",
            "🕐 Start time: 2025-06-01 23:13:08\n",
            "📦 Installing dependencies...\n",
            "✅ Dependencies installed\n",
            "🔧 Setting up Colab environment...\n",
            "🔗 Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "✅ Google Drive mounted successfully\n",
            "📁 Using Google Drive storage: /content/drive/MyDrive/DiffLlama_Experiment\n",
            "  ✓ cache -> /content/drive/MyDrive/DiffLlama_Experiment/models\n",
            "  ✓ data -> /content/drive/MyDrive/DiffLlama_Experiment/data\n",
            "  ✓ results -> /content/drive/MyDrive/DiffLlama_Experiment/results\n",
            "✅ Setup completed\n"
          ]
        }
      ],
      "source": [
        "# 运行初始设置 (包含 Google Drive 挂载)\n",
        "!python colab/experiment.py --setup --use-drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gziSZrcrxTug",
        "outputId": "c4e143b4-756e-4a91-f5d7-9d4594e8a525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 100\n",
            "drwxr-xr-x 1 root root  4096 Jun  1 23:14 .\n",
            "drwxr-xr-x 1 root root  4096 Jun  1 23:06 ..\n",
            "lrwxrwxrwx 1 root root    50 Jun  1 23:14 cache -> /content/drive/MyDrive/DiffLlama_Experiment/models\n",
            "drwxr-xr-x 2 root root  4096 Jun  1 23:14 colab\n",
            "drwxr-xr-x 4 root root  4096 May 29 14:01 .config\n",
            "lrwxrwxrwx 1 root root    48 Jun  1 23:14 data -> /content/drive/MyDrive/DiffLlama_Experiment/data\n",
            "-rw-r--r-- 1 root root 16921 Jun  1 23:07 DiffLlama_Colab_Experiment.ipynb\n",
            "drwxr-xr-x 2 root root  4096 Jun  1 23:07 docs\n",
            "drwx------ 6 root root  4096 Jun  1 23:10 drive\n",
            "-rw-r--r-- 1 root root  2663 Jun  1 23:07 interactive_inference.py\n",
            "-rw-r--r-- 1 root root  1074 Jun  1 23:07 LICENSE\n",
            "-rw-r--r-- 1 root root 16092 Jun  1 23:07 main.py\n",
            "drwxr-xr-x 2 root root  4096 Jun  1 23:11 models_finetuned\n",
            "-rw-r--r-- 1 root root  8948 Jun  1 23:07 README.md\n",
            "-rw-r--r-- 1 root root   219 Jun  1 23:13 requirements.txt\n",
            "lrwxrwxrwx 1 root root    51 Jun  1 23:14 results -> /content/drive/MyDrive/DiffLlama_Experiment/results\n",
            "drwxr-xr-x 1 root root  4096 May 29 14:01 sample_data\n",
            "drwxr-xr-x 2 root root  4096 Jun  1 23:07 scripts\n",
            "drwxr-xr-x 2 root root  4096 Jun  1 23:07 src\n"
          ]
        }
      ],
      "source": [
        "!ls -al"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "experiment_section"
      },
      "source": [
        "## 🚀 第五步：运行实验\n",
        "\n",
        "根据您的需求选择合适的实验模式："
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quick_test_section"
      },
      "source": [
        "### 🏃 快速测试 (推荐首次运行)\n",
        "使用少量样本验证实验流程，大约需要 30-60 分钟。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "quick_test"
      },
      "outputs": [],
      "source": [
        "# 快速测试模式\n",
        "!python colab/experiment.py --mode quick --use-drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "medium_test_section"
      },
      "source": [
        "### 📊 中等规模实验\n",
        "使用中等数量样本，平衡时间和结果质量。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "medium_test"
      },
      "outputs": [],
      "source": [
        "# 中等规模实验 (运行前请确保快速测试成功)\n",
        "!python colab/experiment.py --mode medium --use-drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "full_test_section"
      },
      "source": [
        "### 🔬 完整实验\n",
        "使用完整数据集进行实验，可能需要数小时。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "full_test"
      },
      "outputs": [],
      "source": [
        "# 完整实验 (仅在有足够时间时运行)\n",
        "!python colab/experiment.py --mode full --use-drive --max-samples 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "custom_section"
      },
      "source": [
        "### 🛠 自定义实验\n",
        "根据需要调整实验参数。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "custom_experiment"
      },
      "outputs": [],
      "source": [
        "# 自定义实验示例\n",
        "# 只运行评估，跳过注意力分析以节省时间\n",
        "!python colab/experiment.pyy --mode medium --use-drive --skip-attention --max-samples 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "results_section"
      },
      "source": [
        "## 📊 第六步：查看实验结果\n",
        "\n",
        "实验完成后，查看生成的结果文件。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "list_results"
      },
      "outputs": [],
      "source": [
        "# 列出生成的结果文件\n",
        "!ls -la results/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "show_summary"
      },
      "outputs": [],
      "source": [
        "# 查看最新的实验摘要\n",
        "import json\n",
        "import glob\n",
        "\n",
        "# 找到最新的摘要文件\n",
        "summary_files = glob.glob('results/colab_summary_*.json')\n",
        "if summary_files:\n",
        "    latest_summary = max(summary_files)\n",
        "    print(f\"📋 Latest experiment summary: {latest_summary}\")\n",
        "\n",
        "    with open(latest_summary, 'r') as f:\n",
        "        summary = json.load(f)\n",
        "\n",
        "    print(\"\\n📊 Experiment Summary:\")\n",
        "    for key, value in summary.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "else:\n",
        "    print(\"No experiment summary found. Please run an experiment first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "show_results"
      },
      "outputs": [],
      "source": [
        "# 显示主要结果\n",
        "import pandas as pd\n",
        "\n",
        "# 找到最新的结果文件\n",
        "result_files = glob.glob('results/colab_results_*.csv')\n",
        "if result_files:\n",
        "    latest_results = max(result_files)\n",
        "    print(f\"📈 Latest results: {latest_results}\")\n",
        "\n",
        "    df = pd.read_csv(latest_results)\n",
        "    print(\"\\n📊 Performance Comparison:\")\n",
        "    print(df.pivot(index='model', columns='dataset', values='accuracy'))\n",
        "\n",
        "    # 计算性能差异\n",
        "    pivot_df = df.pivot(index='model', columns='dataset', values='accuracy')\n",
        "    if 'llama' in pivot_df.index and 'diffllama' in pivot_df.index:\n",
        "        print(\"\\n🔍 Performance Difference (DiffLlama - Llama):\")\n",
        "        diff = pivot_df.loc['diffllama'] - pivot_df.loc['llama']\n",
        "        print(diff)\n",
        "else:\n",
        "    print(\"No results found. Please run an experiment first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization_section"
      },
      "source": [
        "## 📈 第七步：结果可视化\n",
        "\n",
        "如果实验包含了注意力分析，可以查看生成的注意力热力图。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "show_attention_maps"
      },
      "outputs": [],
      "source": [
        "# 显示注意力热力图\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "attention_dir = 'results/attention_maps'\n",
        "if os.path.exists(attention_dir):\n",
        "    print(\"🧠 Attention Visualization Files:\")\n",
        "\n",
        "    # 列出所有注意力图文件\n",
        "    for root, dirs, files in os.walk(attention_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.png'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                print(f\"  📊 {file_path}\")\n",
        "\n",
        "                # 显示图片 (可选，取消注释以显示)\n",
        "                # display(Image(file_path))\n",
        "else:\n",
        "    print(\"No attention maps found. Run experiment with attention analysis enabled.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "show_attention_analysis"
      },
      "outputs": [],
      "source": [
        "# 显示注意力分析结果\n",
        "attention_files = glob.glob('results/colab_attention_*.json')\n",
        "if attention_files:\n",
        "    latest_attention = max(attention_files)\n",
        "    print(f\"🧠 Latest attention analysis: {latest_attention}\")\n",
        "\n",
        "    with open(latest_attention, 'r') as f:\n",
        "        attention_data = json.load(f)\n",
        "\n",
        "    print(\"\\n📊 Attention Allocation Analysis:\")\n",
        "    for model, data in attention_data.items():\n",
        "        print(f\"\\n{model.upper()} Model:\")\n",
        "        for condition, stats in data.items():\n",
        "            print(f\"  {condition.capitalize()}:\")\n",
        "            print(f\"    KMI (Key Math Info): {stats['kmi_mean']:.3f} ± {stats['kmi_std']:.3f}\")\n",
        "            print(f\"    NI (Noise Info): {stats['ni_mean']:.3f} ± {stats['ni_std']:.3f}\")\n",
        "            print(f\"    OC (Other Context): {stats['oc_mean']:.3f} ± {stats['oc_std']:.3f}\")\n",
        "else:\n",
        "    print(\"No attention analysis found. Run experiment with attention analysis enabled.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download_section"
      },
      "source": [
        "## 💾 第八步：下载结果\n",
        "\n",
        "将实验结果下载到本地或确保保存在 Google Drive 中。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_results"
      },
      "outputs": [],
      "source": [
        "# 压缩结果文件以便下载\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "zip_filename = f'experiment_results_{timestamp}.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    # 添加结果目录中的所有文件\n",
        "    for root, dirs, files in os.walk('results'):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            zipf.write(file_path)\n",
        "\n",
        "print(f\"📦 Results packaged in: {zip_filename}\")\n",
        "print(\"You can download this file from Colab's Files panel.\")\n",
        "\n",
        "# 如果使用了 Google Drive，提醒用户\n",
        "if os.path.exists('/content/drive/MyDrive/DiffLlama_Experiment'):\n",
        "    print(\"\\n💾 Results are also saved in Google Drive:\")\n",
        "    print(\"  /content/drive/MyDrive/DiffLlama_Experiment/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "troubleshooting_section"
      },
      "source": [
        "## 🛠 故障排除\n",
        "\n",
        "如果遇到问题，尝试以下解决方案："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clear_cache"
      },
      "outputs": [],
      "source": [
        "# 清理 GPU 内存缓存\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"✅ GPU cache cleared\")\n",
        "\n",
        "# 检查可用内存\n",
        "import psutil\n",
        "memory = psutil.virtual_memory()\n",
        "print(f\"💾 RAM: {memory.available / 1e9:.1f}GB available / {memory.total / 1e9:.1f}GB total\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "restart_runtime"
      },
      "outputs": [],
      "source": [
        "# 如果内存不足，可以重启运行时 (谨慎使用)\n",
        "# import os\n",
        "# os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion_section"
      },
      "source": [
        "## 🎯 实验结论\n",
        "\n",
        "根据实验结果，您可以分析以下关键问题：\n",
        "\n",
        "1. **噪声鲁棒性**: DiffLlama 是否在含噪数据上表现更好？\n",
        "2. **注意力机制**: 差分注意力是否更有效地聚焦关键信息？\n",
        "3. **性能下降**: 两个模型在不同噪声类型下的性能变化如何？\n",
        "\n",
        "---\n",
        "\n",
        "**感谢使用此实验框架！** 🎉\n",
        "\n",
        "如有问题，请检查：\n",
        "- GPU 内存是否充足\n",
        "- 所有必需文件是否上传\n",
        "- 网络连接是否稳定\n",
        "\n",
        "**提示**: 建议先运行快速测试模式验证环境，再进行完整实验。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}