# ğŸ“– DiffLlama vs Llama å®éªŒä½¿ç”¨æŒ‡å—

æœ¬æŒ‡å—è¯¦ç»†è¯´æ˜äº†å¦‚ä½•ä½¿ç”¨ DiffLlama vs Llama å™ªå£°é²æ£’æ€§å®éªŒæ¡†æ¶ï¼ŒåŒ…æ‹¬è®¾ç½®ã€è¿è¡Œå’Œåˆ†æç»“æœçš„å®Œæ•´æµç¨‹ã€‚

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒæ£€æŸ¥
é¦–å…ˆéªŒè¯ç¯å¢ƒæ˜¯å¦æ­£ç¡®é…ç½®ï¼š

```bash
# è¿è¡Œç¯å¢ƒæµ‹è¯•
python scripts/test_setup.py

# å¿«é€Ÿæµ‹è¯•æ¨¡å¼
python scripts/test_setup.py --quick
```

### 2. ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚æœéœ€è¦ï¼‰
```bash
# ä¸‹è½½å®éªŒæ‰€éœ€çš„æ¨¡å‹
python scripts/download_models.py
```

### 3. è¿è¡Œå¿«é€Ÿå®éªŒ
```bash
# è¿è¡ŒåŒ…å«20ä¸ªæ ·æœ¬çš„å¿«é€Ÿæµ‹è¯•
python main.py --quick-test
```

## ğŸ”§ è¯¦ç»†ä½¿ç”¨è¯´æ˜

### å‘½ä»¤è¡Œå‚æ•°

#### ä¸»å®éªŒè„šæœ¬ (`main.py`)

```bash
python main.py [OPTIONS]
```

**ä¸»è¦é€‰é¡¹:**
- `--quick-test`: è¿è¡Œå¿«é€Ÿæµ‹è¯•ï¼ˆ20ä¸ªæ ·æœ¬ï¼‰
- `--max-samples N`: é™åˆ¶æ¯ä¸ªæ•°æ®é›†çš„æœ€å¤§æ ·æœ¬æ•°
- `--skip-data-gen`: è·³è¿‡æ•°æ®ç”Ÿæˆï¼ˆä½¿ç”¨ç°æœ‰æ•°æ®ï¼‰
- `--skip-evaluation`: è·³è¿‡é›¶æ ·æœ¬è¯„ä¼°
- `--skip-sft`: è·³è¿‡ç›‘ç£å¾®è°ƒ
- `--skip-attention`: è·³è¿‡æ³¨æ„åŠ›åˆ†æ
- `--models MODEL1,MODEL2`: æŒ‡å®šè¦æµ‹è¯•çš„æ¨¡å‹ï¼ˆé»˜è®¤: diffllama,llamaï¼‰
- `--datasets DATASET1,DATASET2`: æŒ‡å®šè¦æµ‹è¯•çš„æ•°æ®é›†ï¼ˆé»˜è®¤: clean,inf,rcs,sdï¼‰

**ç¤ºä¾‹ç”¨æ³•:**
```bash
# å®Œæ•´å®éªŒ
python main.py

# è‡ªå®šä¹‰æ ·æœ¬æ•°é‡
python main.py --max-samples 100

# è·³è¿‡è€—æ—¶çš„å¾®è°ƒæ­¥éª¤
python main.py --skip-sft

# åªæµ‹è¯•ç‰¹å®šæ•°æ®é›†
python main.py --datasets clean,inf

# åªæµ‹è¯•ç‰¹å®šæ¨¡å‹
python main.py --models diffllama
```

#### Colab å®éªŒè„šæœ¬ (`colab/experiment.py`)

```bash
python colab/experiment.py [OPTIONS]
```

**Colab ç‰¹å®šé€‰é¡¹:**
- `--mode {quick,medium,full}`: å®éªŒæ¨¡å¼
- `--use-drive`: ä½¿ç”¨ Google Drive æŒä¹…å­˜å‚¨
- `--setup`: ä»…æ‰§è¡Œç¯å¢ƒè®¾ç½®
- `--instructions`: æ˜¾ç¤ºä½¿ç”¨è¯´æ˜

**ç¤ºä¾‹ç”¨æ³•:**
```bash
# Colab å¿«é€Ÿæµ‹è¯•
python colab/experiment.py --mode quick --use-drive

# Colab å®Œæ•´å®éªŒ
python colab/experiment.py --mode full --use-drive --max-samples 500
```

### å®éªŒæ¨¡å¼

#### 1. å¿«é€Ÿæµ‹è¯•æ¨¡å¼
- **ç”¨é€”**: éªŒè¯ç¯å¢ƒé…ç½®å’Œä»£ç æ­£ç¡®æ€§
- **æ ·æœ¬æ•°**: 20ä¸ª/æ•°æ®é›†
- **è¿è¡Œæ—¶é—´**: 30-60åˆ†é’Ÿ
- **å‘½ä»¤**: `python main.py --quick-test`

#### 2. æ ‡å‡†æ¨¡å¼
- **ç”¨é€”**: å¹³è¡¡çš„å®éªŒç»“æœ
- **æ ·æœ¬æ•°**: 200ä¸ª/æ•°æ®é›†ï¼ˆå¯è‡ªå®šä¹‰ï¼‰
- **è¿è¡Œæ—¶é—´**: 2-4å°æ—¶
- **å‘½ä»¤**: `python main.py`

#### 3. å®Œæ•´æ¨¡å¼
- **ç”¨é€”**: å®Œæ•´çš„ç ”ç©¶ç»“æœ
- **æ ·æœ¬æ•°**: å…¨éƒ¨æ•°æ®ï¼ˆ~1300ä¸ªï¼‰
- **è¿è¡Œæ—¶é—´**: 6-12å°æ—¶
- **å‘½ä»¤**: `python main.py --max-samples -1`

## ğŸ“Š æ•°æ®é›†è¯´æ˜

### åŸå§‹æ•°æ®é›†
- **Clean**: GSM8K åŸå§‹æµ‹è¯•é›†
- **å¤§å°**: 1,319ä¸ªæ•°å­¦é—®é¢˜

### å™ªå£°æ•°æ®é›†
- **INF** (Irrelevant Numbers/Facts): æ·»åŠ æ— å…³æ•°å­—å’Œäº‹å®
- **RCS** (Redundant Calculation Steps): æ·»åŠ å†—ä½™è®¡ç®—æ­¥éª¤  
- **SD** (Semantic Distraction): æ·»åŠ è¯­ä¹‰å¹²æ‰°ä¿¡æ¯

æ¯ä¸ªå™ªå£°æ•°æ®é›†éƒ½åŸºäºåŸå§‹ Clean æ•°æ®é›†ç”Ÿæˆã€‚

## ğŸ¤– æ¨¡å‹è¯´æ˜

### DiffLlama-375M
- **ç±»å‹**: åŸºäºå·®åˆ†æ³¨æ„åŠ›æœºåˆ¶çš„ Llama å˜ä½“
- **å‚æ•°é‡**: 375M
- **ç‰¹ç‚¹**: å…·æœ‰ä¸“é—¨çš„å·®åˆ†æ³¨æ„åŠ›æœºåˆ¶

### Llama-375M  
- **ç±»å‹**: æ ‡å‡† Llama æ¶æ„
- **å‚æ•°é‡**: 375M
- **ç‰¹ç‚¹**: ä¼ ç»Ÿçš„æ³¨æ„åŠ›æœºåˆ¶

## ğŸ“ˆ ç»“æœåˆ†æ

### è¾“å‡ºæ–‡ä»¶

å®éªŒå®Œæˆåï¼Œç»“æœä¿å­˜åœ¨ `results/` ç›®å½•ï¼š

```
results/
â”œâ”€â”€ experiment_results_[timestamp].csv     # ä¸»è¦æ€§èƒ½ç»“æœ
â”œâ”€â”€ detailed_results_[timestamp].json      # è¯¦ç»†ç»“æœ
â”œâ”€â”€ attention_analysis_[timestamp].json    # æ³¨æ„åŠ›åˆ†æ
â”œâ”€â”€ model_comparison_[timestamp].png       # æ€§èƒ½å¯¹æ¯”å›¾
â””â”€â”€ attention_maps/                        # æ³¨æ„åŠ›çƒ­åŠ›å›¾
    â”œâ”€â”€ clean_samples/
    â”œâ”€â”€ inf_samples/
    â”œâ”€â”€ rcs_samples/
    â””â”€â”€ sd_samples/
```

### æ€§èƒ½æŒ‡æ ‡

#### Pass@1 å‡†ç¡®ç‡
- æ¨¡å‹ç¬¬ä¸€æ¬¡å°è¯•ç»™å‡ºæ­£ç¡®ç­”æ¡ˆçš„æ¯”ä¾‹
- ä¸»è¦è¯„ä¼°æŒ‡æ ‡

#### æ³¨æ„åŠ›åˆ†ææŒ‡æ ‡
- **KMIæ¯”ä¾‹**: å…³é”®æ•°å­¦ä¿¡æ¯çš„æ³¨æ„åŠ›å æ¯”
- **NIæ¯”ä¾‹**: å™ªå£°ä¿¡æ¯çš„æ³¨æ„åŠ›å æ¯”  
- **OCæ¯”ä¾‹**: å…¶ä»–å†…å®¹çš„æ³¨æ„åŠ›å æ¯”

### è§£è¯»ç»“æœ

#### æ€§èƒ½å¯¹æ¯”è¡¨æ ¼ç¤ºä¾‹
```
           Clean    INF      RCS      SD
llama      0.145    0.098    0.110    0.105
diffllama  0.162    0.123    0.135    0.128
```

**è§£è¯»:**
- DiffLlama åœ¨æ‰€æœ‰æ•°æ®é›†ä¸Šéƒ½ä¼˜äº Llama
- å™ªå£°æ˜¾è‘—é™ä½äº†ä¸¤ä¸ªæ¨¡å‹çš„æ€§èƒ½
- DiffLlama åœ¨å™ªå£°æ•°æ®ä¸Šçš„æ€§èƒ½ä¸‹é™è¾ƒå°

#### æ³¨æ„åŠ›åˆ†æç¤ºä¾‹
```json
{
  "llama": {
    "clean": {"kmi_ratio": 0.45, "ni_ratio": 0.0, "oc_ratio": 0.55},
    "inf": {"kmi_ratio": 0.32, "ni_ratio": 0.18, "oc_ratio": 0.50}
  },
  "diffllama": {
    "clean": {"kmi_ratio": 0.50, "ni_ratio": 0.0, "oc_ratio": 0.50},
    "inf": {"kmi_ratio": 0.43, "ni_ratio": 0.12, "oc_ratio": 0.45}
  }
}
```

**è§£è¯»:**
- DiffLlama èƒ½æ›´å¥½åœ°å…³æ³¨å…³é”®æ•°å­¦ä¿¡æ¯ï¼ˆKMIï¼‰
- é¢å¯¹å™ªå£°æ—¶ï¼ŒDiffLlama çš„æ³¨æ„åŠ›åˆ†æ•£ç¨‹åº¦è¾ƒå°
- è¯æ˜äº†å·®åˆ†æ³¨æ„åŠ›æœºåˆ¶çš„æœ‰æ•ˆæ€§

## ğŸ›  é«˜çº§ä½¿ç”¨

### è‡ªå®šä¹‰é…ç½®

ç¼–è¾‘é…ç½®æ–‡ä»¶ä»¥è‡ªå®šä¹‰å®éªŒå‚æ•°ï¼š

```python
# src/config.py (å¦‚æœå­˜åœ¨)
GENERATION_CONFIG = {
    "max_new_tokens": 512,
    "temperature": 0.1,
    "top_p": 0.95,
    "do_sample": False
}

EVALUATION_CONFIG = {
    "batch_size": 8,
    "max_samples_per_dataset": 200
}
```

### å•ç‹¬è¿è¡Œæ¨¡å—

#### æ•°æ®ç”Ÿæˆ
```python
from src.utils import download_gsm8k
from src.noise_injection import generate_noisy_datasets

# ä¸‹è½½åŸå§‹æ•°æ®
download_gsm8k()

# ç”Ÿæˆå™ªå£°æ•°æ®é›†
generate_noisy_datasets()
```

#### æ¨¡å‹è¯„ä¼°
```python
from src.evaluation import run_comprehensive_evaluation

# è¿è¡Œè¯„ä¼°
results_df, detailed_results = run_comprehensive_evaluation(
    models=['diffllama', 'llama'],
    datasets=['clean', 'inf'],
    max_samples_per_dataset=50
)
```

#### æ³¨æ„åŠ›åˆ†æ
```python
from src.attention_visualizer import compare_attention_patterns

# æ¯”è¾ƒæ³¨æ„åŠ›æ¨¡å¼
results = compare_attention_patterns(
    clean_dataset="data/gsm8k_test.jsonl",
    noisy_dataset="data/gsm8k_inf_test.jsonl",
    num_samples=10
)
```

### æ·»åŠ æ–°çš„å™ªå£°ç±»å‹

å®ç°æ–°çš„å™ªå£°æ³¨å…¥å‡½æ•°ï¼š

```python
# src/noise_injection.py
def inject_custom_noise(question):
    """Custom noise injection function"""
    # Implement your noise injection logic
    return modified_question

# In generation script
def generate_custom_noisy_dataset():
    """Generate custom noisy dataset"""
    # Use your noise function to generate dataset
    pass
```

## ğŸ› æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. CUDA å†…å­˜ä¸è¶³
```bash
# è§£å†³æ–¹æ¡ˆï¼šå‡å°‘æ‰¹é‡å¤§å°æˆ–æ ·æœ¬æ•°
python main.py --quick-test --max-samples 10
```

#### 2. æ¨¡å‹ä¸‹è½½å¤±è´¥
```bash
# æ‰‹åŠ¨ä¸‹è½½æ¨¡å‹
python scripts/download_models.py

# æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œ Hugging Face è®¿é—®
```

#### 3. å¯¼å…¥é”™è¯¯
```bash
# æ£€æŸ¥ç¯å¢ƒé…ç½®
python scripts/test_setup.py

# å®‰è£…ç¼ºå¤±çš„ä¾èµ–
pip install -r requirements.txt
```

#### 4. æ•°æ®ç”Ÿæˆå¤±è´¥
```bash
# æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œæ•°æ®ç›®å½•æƒé™
ls -la data/

# æ‰‹åŠ¨ä¸‹è½½ GSM8K
python -c "from src.utils import download_gsm8k; download_gsm8k()"
```

### æ€§èƒ½ä¼˜åŒ–

#### GPU ä¼˜åŒ–
```python
# å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆå¦‚æœæ”¯æŒï¼‰
import torch
torch.backends.cudnn.benchmark = True
```

#### å†…å­˜ä¼˜åŒ–
```python
# æ¸…ç† GPU ç¼“å­˜
import torch
torch.cuda.empty_cache()

# ä½¿ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹ï¼ˆå¦‚é€‚ç”¨ï¼‰
```

## ğŸ“š æ‰©å±•å®éªŒ

### æ·»åŠ æ–°æ¨¡å‹

1. åœ¨ `src/model_loader.py` ä¸­æ·»åŠ æ¨¡å‹åŠ è½½é€»è¾‘
2. æ›´æ–°é…ç½®ä»¥åŒ…å«æ–°æ¨¡å‹
3. è¿è¡Œå®éªŒï¼š`python main.py --models your_model,diffllama,llama`

### æ·»åŠ æ–°æ•°æ®é›†

1. åœ¨ `src/utils.py` ä¸­æ·»åŠ æ•°æ®ä¸‹è½½å‡½æ•°
2. åœ¨ `src/noise_injection.py` ä¸­æ·»åŠ å¯¹åº”çš„å™ªå£°ç”Ÿæˆ
3. æ›´æ–°è¯„ä¼°æµç¨‹ä»¥æ”¯æŒæ–°æ•°æ®é›†

### è‡ªå®šä¹‰è¯„ä¼°æŒ‡æ ‡

1. åœ¨ `src/evaluation.py` ä¸­æ·»åŠ æ–°çš„è¯„ä¼°å‡½æ•°
2. ä¿®æ”¹ç»“æœèšåˆé€»è¾‘
3. æ›´æ–°ç»“æœå¯è§†åŒ–

## ğŸ“ å­¦æœ¯ä½¿ç”¨

### å¼•ç”¨æ ¼å¼
å¦‚æœåœ¨å­¦æœ¯å·¥ä½œä¸­ä½¿ç”¨æ­¤æ¡†æ¶ï¼Œè¯·è€ƒè™‘å¼•ç”¨ç›¸å…³è®ºæ–‡å’Œæ•°æ®é›†ã€‚

### å®éªŒå¤ç°
ä¸ºç¡®ä¿å®éªŒå¯å¤ç°ï¼š
1. è®°å½•æ‰€ä½¿ç”¨çš„æ¨¡å‹ç‰ˆæœ¬
2. ä¿å­˜éšæœºç§å­è®¾ç½®
3. è®°å½•ç¡¬ä»¶é…ç½®ä¿¡æ¯
4. ä¿å­˜å®Œæ•´çš„ç»“æœæ–‡ä»¶

---

**æ›´å¤šå¸®åŠ©:**
- æŸ¥çœ‹ `README.md` äº†è§£é¡¹ç›®æ¦‚è§ˆ
- æŸ¥çœ‹ `colab/README.md` äº†è§£ Colab ä½¿ç”¨
- è¿è¡Œ `python main.py --help` æŸ¥çœ‹æ‰€æœ‰é€‰é¡¹ 