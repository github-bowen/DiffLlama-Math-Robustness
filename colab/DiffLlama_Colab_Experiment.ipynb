{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# üî¨ DiffLlama vs Llama: Google Colab Experiment\n",
        "\n",
        "This Notebook is designed to run a comparative experiment on Google Colab environment to evaluate the noise robustness of DiffLlama and Llama on mathematical reasoning tasks.\n",
        "\n",
        "## üìã Experiment Overview\n",
        "- **Objective**: Compare DiffLlama-375M and Llama-375M performance on noisy math problems\n",
        "- **Dataset**: GSM8K math reasoning dataset and its noisy variants\n",
        "- **Evaluation**: Zero-shot performance + attention mechanism analysis\n",
        "- **Environment**: Google Colab (GPU recommended)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_section"
      },
      "source": [
        "## üöÄ Step 1: Environment Setup\n",
        "\n",
        "First, check the runtime environment and configure necessary settings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "check_environment",
        "outputId": "fc3636ae-b502-48c7-80f3-8c06a087c830"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üñ•Ô∏è  CUDA available: False\n",
            "‚ö†Ô∏è  No GPU detected. Experiment will be slow on CPU.\n"
          ]
        }
      ],
      "source": [
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"üñ•Ô∏è  CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üîß GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è  No GPU detected. Experiment will be slow on CPU.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clone_repo",
        "outputId": "3f8dc053-13bf-4be3-832e-6e74ed7ef47a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Project files found\n"
          ]
        }
      ],
      "source": [
        "# Clone from Git repository if project files are not in current directory\n",
        "# Replace with your actual repository URL\n",
        "import os\n",
        "if not os.path.exists('colab/experiment.py'):\n",
        "    print(\"üì• Cloning repository...\")\n",
        "    !git clone https://github.com/github-bowen/DiffLlama-Math-Robustness.git\n",
        "    print(\"üì• Copying files...\")\n",
        "    !cp -r DiffLlama-Math-Robustness/* .\n",
        "    print(\"üì• Removing repository...\")\n",
        "    !rm -rf DiffLlama-Math-Robustness\n",
        "    print(\"üì• Done\")\n",
        "else:\n",
        "    print(\"‚úÖ Project files found\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upload_section"
      },
      "source": [
        "## üìÅ Step 2: Upload Project Files\n",
        "\n",
        "If you didn't clone using Git, manually upload the following files to Colab:\n",
        "\n",
        "**Required Files**:\n",
        "- `colab_experiment.py` (main Colab script)\n",
        "- `pre_download_models.py` (model download script)\n",
        "- All Python files in the `src/` directory\n",
        "- `requirements.txt`\n",
        "\n",
        "Use Colab's file upload feature or copy files from Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "instructions_section"
      },
      "source": [
        "## üìñ Step 3: View Usage Instructions\n",
        "\n",
        "Run the command below to view detailed usage instructions and options."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "show_instructions",
        "outputId": "acd9be1d-4cd1-4027-8214-1584d3a43e9e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "üéØ GOOGLE COLAB USAGE INSTRUCTIONS\n",
            "\n",
            "1. üì± Basic Setup (Run once):\n",
            "   !python colab/experiment.py --setup\n",
            "\n",
            "2. üöÄ Quick Test (Recommended first run):\n",
            "   !python colab/experiment.py --mode quick\n",
            "\n",
            "3. üìä Medium Experiment:\n",
            "   !python colab/experiment.py --mode medium\n",
            "\n",
            "4. üî¨ Full Experiment:\n",
            "   !python colab/experiment.py --mode full --max-samples 500\n",
            "\n",
            "üîß Options:\n",
            "   --mode: quick/medium/full\n",
            "  : Save models and results to Google Drive\n",
            "   --max-samples: Limit number of evaluation samples\n",
            "   --skip-attention: Skip attention analysis to save time\n",
            "   --help: Show all options\n",
            "\n",
            "üí° Tips:\n",
            "   - Use to persist models across sessions\n",
            "   - Start with quick mode to verify everything works\n",
            "   - Monitor GPU memory usage in Colab\n",
            "\n",
            "üìÅ Results will be saved to:\n",
            "   - Local: /content/results/\n",
            "   - Drive: /content/drive/MyDrive/DiffLlama_Experiment/results/\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Display usage instructions\n",
        "!python colab/experiment.py --instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup_run_section"
      },
      "source": [
        "## üîß Step 4: Initial Setup\n",
        "\n",
        "Run initial setup to install dependencies and configure the environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lq8duQXXpnBa",
        "outputId": "5824dab8-d1af-4c77-c2db-ebbcf514407c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "initial_setup",
        "outputId": "142da218-3b51-417a-e4f5-1ead00f358ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "================================================================================\n",
            "üî¨ DIFFLAMA VS LLAMA - GOOGLE COLAB EXPERIMENT\n",
            "================================================================================\n",
            "üïê Start time: 2025-06-01 23:13:08\n",
            "üì¶ Installing dependencies...\n",
            "‚úÖ Dependencies installed\n",
            "üîß Setting up Colab environment...\n",
            "üîó Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "‚úÖ Google Drive mounted successfully\n",
            "üìÅ Using Google Drive storage: /content/drive/MyDrive/DiffLlama_Experiment\n",
            "  ‚úì cache -> /content/drive/MyDrive/DiffLlama_Experiment/models\n",
            "  ‚úì data -> /content/drive/MyDrive/DiffLlama_Experiment/data\n",
            "  ‚úì results -> /content/drive/MyDrive/DiffLlama_Experiment/results\n",
            "‚úÖ Setup completed\n"
          ]
        }
      ],
      "source": [
        "# Run initial setup (includes Google Drive mounting)\n",
        "!python colab/experiment.py --setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gziSZrcrxTug",
        "outputId": "c4e143b4-756e-4a91-f5d7-9d4594e8a525"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 100\n",
            "drwxr-xr-x 1 root root  4096 Jun  1 23:14 .\n",
            "drwxr-xr-x 1 root root  4096 Jun  1 23:06 ..\n",
            "lrwxrwxrwx 1 root root    50 Jun  1 23:14 cache -> /content/drive/MyDrive/DiffLlama_Experiment/models\n",
            "drwxr-xr-x 2 root root  4096 Jun  1 23:14 colab\n",
            "drwxr-xr-x 4 root root  4096 May 29 14:01 .config\n",
            "lrwxrwxrwx 1 root root    48 Jun  1 23:14 data -> /content/drive/MyDrive/DiffLlama_Experiment/data\n",
            "-rw-r--r-- 1 root root 16921 Jun  1 23:07 DiffLlama_Colab_Experiment.ipynb\n",
            "drwxr-xr-x 2 root root  4096 Jun  1 23:07 docs\n",
            "drwx------ 6 root root  4096 Jun  1 23:10 drive\n",
            "-rw-r--r-- 1 root root  2663 Jun  1 23:07 interactive_inference.py\n",
            "-rw-r--r-- 1 root root  1074 Jun  1 23:07 LICENSE\n",
            "-rw-r--r-- 1 root root 16092 Jun  1 23:07 main.py\n",
            "drwxr-xr-x 2 root root  4096 Jun  1 23:11 models_finetuned\n",
            "-rw-r--r-- 1 root root  8948 Jun  1 23:07 README.md\n",
            "-rw-r--r-- 1 root root   219 Jun  1 23:13 requirements.txt\n",
            "lrwxrwxrwx 1 root root    51 Jun  1 23:14 results -> /content/drive/MyDrive/DiffLlama_Experiment/results\n",
            "drwxr-xr-x 1 root root  4096 May 29 14:01 sample_data\n",
            "drwxr-xr-x 2 root root  4096 Jun  1 23:07 scripts\n",
            "drwxr-xr-x 2 root root  4096 Jun  1 23:07 src\n"
          ]
        }
      ],
      "source": [
        "!ls -al"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "experiment_section"
      },
      "source": [
        "## üöÄ Step 5: Run Experiments\n",
        "\n",
        "Choose an appropriate experiment mode based on your needs:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quick_test_section"
      },
      "source": [
        "### üèÉ Quick Test (Recommended for First Run)\n",
        "Validate the experiment workflow using a small number of samples, takes about 30-60 minutes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "quick_test"
      },
      "outputs": [],
      "source": [
        "# Quick test mode\n",
        "!python colab/experiment.py --mode quick"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "medium_test_section"
      },
      "source": [
        "### üìä Medium-Scale Experiment\n",
        "Use a moderate number of samples, balancing time and result quality."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "medium_test"
      },
      "outputs": [],
      "source": [
        "# Medium-scale experiment (make sure quick test runs successfully first)\n",
        "!python colab/experiment.py --mode medium"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "full_test_section"
      },
      "source": [
        "### üî¨ Full Experiment\n",
        "Use the complete dataset for the experiment, may take several hours."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "full_test"
      },
      "outputs": [],
      "source": [
        "# Full experiment (run only when you have enough time)\n",
        "!python colab/experiment.py --mode full --max-samples 500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "custom_section"
      },
      "source": [
        "### üõ† Custom Experiment\n",
        "Adjust experiment parameters as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "custom_experiment"
      },
      "outputs": [],
      "source": [
        "# Custom experiment example\n",
        "# Only run evaluation, skip attention analysis to save time\n",
        "!python colab/experiment.pyy --mode medium --skip-attention --max-samples 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "results_section"
      },
      "source": [
        "## üìä Step 6: View Experiment Results\n",
        "\n",
        "After completing the experiment, review the generated result files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "list_results"
      },
      "outputs": [],
      "source": [
        "# List generated result files\n",
        "!ls -la results/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "show_summary"
      },
      "outputs": [],
      "source": [
        "# View the latest experiment summary\n",
        "import json\n",
        "import glob\n",
        "\n",
        "# Find the latest summary file\n",
        "summary_files = glob.glob('results/colab_summary_*.json')\n",
        "if summary_files:\n",
        "    latest_summary = max(summary_files)\n",
        "    print(f\"üìã Latest experiment summary: {latest_summary}\")\n",
        "\n",
        "    with open(latest_summary, 'r') as f:\n",
        "        summary = json.load(f)\n",
        "\n",
        "    print(\"\\nüìä Experiment Summary:\")\n",
        "    for key, value in summary.items():\n",
        "        print(f\"  {key}: {value}\")\n",
        "else:\n",
        "    print(\"No experiment summary found. Please run an experiment first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "show_results"
      },
      "outputs": [],
      "source": [
        "# Display main results\n",
        "import pandas as pd\n",
        "\n",
        "# Find the latest results file\n",
        "result_files = glob.glob('results/colab_results_*.csv')\n",
        "if result_files:\n",
        "    latest_results = max(result_files)\n",
        "    print(f\"üìà Latest results: {latest_results}\")\n",
        "\n",
        "    df = pd.read_csv(latest_results)\n",
        "    print(\"\\nüìä Performance Comparison:\")\n",
        "    print(df.pivot(index='model', columns='dataset', values='accuracy'))\n",
        "\n",
        "    # Calculate performance differences\n",
        "    pivot_df = df.pivot(index='model', columns='dataset', values='accuracy')\n",
        "    if 'llama' in pivot_df.index and 'diffllama' in pivot_df.index:\n",
        "        print(\"\\nüîç Performance Difference (DiffLlama - Llama):\")\n",
        "        diff = pivot_df.loc['diffllama'] - pivot_df.loc['llama']\n",
        "        print(diff)\n",
        "else:\n",
        "    print(\"No results found. Please run an experiment first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualization_section"
      },
      "source": [
        "## üìà Step 7: Results Visualization\n",
        "\n",
        "If your experiment included attention analysis, you can view the generated attention heatmaps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "show_attention_maps"
      },
      "outputs": [],
      "source": [
        "# Display attention heatmaps\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Image, display\n",
        "import os\n",
        "\n",
        "attention_dir = 'results/attention_maps'\n",
        "if os.path.exists(attention_dir):\n",
        "    print(\"üß† Attention Visualization Files:\")\n",
        "\n",
        "    # List all attention map files\n",
        "    for root, dirs, files in os.walk(attention_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.png'):\n",
        "                file_path = os.path.join(root, file)\n",
        "                print(f\"  üìä {file_path}\")\n",
        "\n",
        "                # Display images (optional, uncomment to show)\n",
        "                # display(Image(file_path))\n",
        "else:\n",
        "    print(\"No attention maps found. Run experiment with attention analysis enabled.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "show_attention_analysis"
      },
      "outputs": [],
      "source": [
        "# Display attention analysis results\n",
        "attention_files = glob.glob('results/colab_attention_*.json')\n",
        "if attention_files:\n",
        "    latest_attention = max(attention_files)\n",
        "    print(f\"üß† Latest attention analysis: {latest_attention}\")\n",
        "\n",
        "    with open(latest_attention, 'r') as f:\n",
        "        attention_data = json.load(f)\n",
        "\n",
        "    print(\"\\nüìä Attention Allocation Analysis:\")\n",
        "    for model, data in attention_data.items():\n",
        "        print(f\"\\n{model.upper()} Model:\")\n",
        "        for condition, stats in data.items():\n",
        "            print(f\"  {condition.capitalize()}:\")\n",
        "            print(f\"    KMI (Key Math Info): {stats['kmi_mean']:.3f} ¬± {stats['kmi_std']:.3f}\")\n",
        "            print(f\"    NI (Noise Info): {stats['ni_mean']:.3f} ¬± {stats['ni_std']:.3f}\")\n",
        "            print(f\"    OC (Other Context): {stats['oc_mean']:.3f} ¬± {stats['oc_std']:.3f}\")\n",
        "else:\n",
        "    print(\"No attention analysis found. Run experiment with attention analysis enabled.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "download_section"
      },
      "source": [
        "## üíæ Step 8: Download Results\n",
        "\n",
        "Download experiment results locally or ensure they are saved in Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "download_results"
      },
      "outputs": [],
      "source": [
        "# Compress result files for download\n",
        "import zipfile\n",
        "from datetime import datetime\n",
        "\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "zip_filename = f'experiment_results_{timestamp}.zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
        "    # Add all files from results directory\n",
        "    for root, dirs, files in os.walk('results'):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            zipf.write(file_path)\n",
        "\n",
        "print(f\"üì¶ Results packaged in: {zip_filename}\")\n",
        "print(\"You can download this file from Colab's Files panel.\")\n",
        "\n",
        "# Reminder if Google Drive was used\n",
        "if os.path.exists('/content/drive/MyDrive/DiffLlama_Experiment'):\n",
        "    print(\"\\nüíæ Results are also saved in Google Drive:\")\n",
        "    print(\"  /content/drive/MyDrive/DiffLlama_Experiment/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "troubleshooting_section"
      },
      "source": [
        "## üõ† Troubleshooting\n",
        "\n",
        "If you encounter issues, try the following solutions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clear_cache"
      },
      "outputs": [],
      "source": [
        "# Clear GPU memory cache\n",
        "import torch\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"‚úÖ GPU cache cleared\")\n",
        "\n",
        "# Check available memory\n",
        "import psutil\n",
        "memory = psutil.virtual_memory()\n",
        "print(f\"üíæ RAM: {memory.available / 1e9:.1f}GB available / {memory.total / 1e9:.1f}GB total\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "restart_runtime"
      },
      "outputs": [],
      "source": [
        "# If memory is insufficient, you can restart the runtime (use with caution)\n",
        "# import os\n",
        "# os.kill(os.getpid(), 9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusion_section"
      },
      "source": [
        "## üéØ Experiment Conclusions\n",
        "\n",
        "Based on the experiment results, you can analyze the following key questions:\n",
        "\n",
        "1. **Noise Robustness**: Does DiffLlama perform better on noisy data?\n",
        "2. **Attention Mechanism**: Is differential attention more effective at focusing on key information?\n",
        "3. **Performance Degradation**: How do both models' performances change across different noise types?\n",
        "\n",
        "---\n",
        "\n",
        "**Thank you for using this experiment framework!** üéâ\n",
        "\n",
        "If you have issues, please check:\n",
        "- If GPU memory is sufficient\n",
        "- If all required files are uploaded\n",
        "- If network connection is stable\n",
        "\n",
        "**Tip**: It's recommended to run the quick test mode first to validate the environment before running the full experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
