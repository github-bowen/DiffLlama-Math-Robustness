# DiffLlama vs Llama Noise Robustness Experiment

A research project on mathematical reasoning noise robustness based on differential attention mechanism, comparing the performance of [DiffLlama-375M](https://huggingface.co/reyllama/DiffLlama-375M) and [Llama-375M](https://huggingface.co/reyllama/Llama_375M) on noisy mathematical problems.

This project is an extension of the work presented in [Differential Transformer](https://arxiv.org/abs/2410.05258), adapted to use small-scale models for mathematical reasoning robustness analysis.

> [!NOTE]
> For usage guide, please refer to [USAGE_GUIDE.md](USAGE_GUIDE.md).

## ğŸ“š Table of Contents

- [DiffLlama vs Llama Noise Robustness Experiment](#diffllama-vs-llama-noise-robustness-experiment)
  - [ğŸ“š Table of Contents](#-table-of-contents)
  - [ğŸ“‹ Project Overview](#-project-overview)
    - [ğŸ¯ Research Objectives](#-research-objectives)
  - [ğŸ—ï¸ Project Structure](#ï¸-project-structure)
    - [Example of Noise Injection](#example-of-noise-injection)
    - [Evaluation Metrics](#evaluation-metrics)
    - [Experiment Modes](#experiment-modes)
      - [1. Quick Test Mode](#1-quick-test-mode)
      - [2. Standard Mode](#2-standard-mode)
      - [3. Full Mode](#3-full-mode)
  - [ğŸ“Š Dataset Description](#-dataset-description)
    - [Original Dataset](#original-dataset)
    - [Noisy Datasets](#noisy-datasets)
  - [ğŸ¤– Model Description](#-model-description)
    - [DiffLlama-375M](#diffllama-375m)
    - [Llama-375M](#llama-375m)
  - [ğŸ“ˆ Result Analysis](#-result-analysis)
    - [Output Files](#output-files)
    - [Performance Metrics](#performance-metrics)
      - [Pass@1 Accuracy](#pass1-accuracy)
      - [Attention Analysis Metrics](#attention-analysis-metrics)
  - [ğŸ“„ License](#-license)

## ğŸ“‹ Project Overview

This project implements a complete experimental framework for studying and comparing the noise robustness of different attention mechanisms in mathematical reasoning tasks. Through systematic experimental design, it deeply explores the advantages of DiffLlama's differential attention mechanism compared to traditional attention mechanisms.

**Paper Reference**: This work extends the differential attention mechanism introduced in *Differential Transformer* ([arXiv:2410.05258](https://arxiv.org/abs/2410.05258)) by applying it to mathematical reasoning tasks using smaller-scale models (375M parameters) to investigate noise robustness properties.

### ğŸ¯ Research Objectives

- **Performance Comparison**: Evaluate DiffLlama and Llama's performance on clean and noisy mathematical problems
- **Noise Robustness**: Analyze the impact of different types of noise on model performance
- **Attention Mechanism**: Visualize and quantify models' attention allocation patterns
- **In-depth Analysis**: Explore the working principles and advantages of differential attention mechanism

## ğŸ—ï¸ Project Structure

```bash
.
â”œâ”€â”€ colab
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ DiffLlama_Colab_Experiment.ipynb
â”‚   â”œâ”€â”€ experiment.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ download_models.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ inspect_model_structure.py
â”‚   â”œâ”€â”€ inspect_attention_allocation_ratio_results.py
â”‚   â”œâ”€â”€ interactive_inference.py
â”‚   â”œâ”€â”€ test_diffllama_attention.py
â”‚   â”œâ”€â”€ test_llama_attention.py
â”‚   â””â”€â”€ test_setup.py
â”œâ”€â”€ src
â”‚   â”œâ”€â”€ attention_visualizer.py
â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”œâ”€â”€ fine_tuning.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ model_loader.py
â”‚   â”œâ”€â”€ noise_injection.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ data
â”œâ”€â”€ LICENSE
â”œâ”€â”€ main.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ USAGE_GUIDE.md
```

### Example of Noise Injection

```bash
Original: "A pizza is cut into 8 slices. If 3 slices are eaten, how many remain?"
Noisy: "A delicious pizza with cheese and pepperoni is cut into 8 equal slices. The pizza smells great. If 3 slices are eaten quickly, how many slices remain on the plate?"
```

### Evaluation Metrics

- **Pass@1 Accuracy**: Model's accuracy on first attempt
- **Attention Allocation Ratio**: Attention proportion for KMI/NI/OC tokens
- **Robustness Degradation**: Performance change from clean to noisy data

### Experiment Modes

#### 1. Quick Test Mode

- **Purpose**: Verify environment configuration and code correctness
- **Sample Count**: 20 per dataset
- **Runtime**: 30-60 minutes
- **Command**: `python -m main --quick-test`

#### 2. Standard Mode

- **Purpose**: Balanced experimental results
- **Sample Count**: 200 per dataset (customizable)
- **Runtime**: 2-4 hours
- **Command**: `python -m main`

#### 3. Full Mode

- **Purpose**: Complete research results
- **Sample Count**: All data (~1300 samples)
- **Runtime**: 6-12 hours
- **Command**: `python -m main --max-samples -1`

## ğŸ“Š Dataset Description

### Original Dataset

- **Clean**: GSM8K original test set
- **Size**: 1,319 math problems

### Noisy Datasets

- **INF** (Irrelevant Numbers/Facts): Add irrelevant numbers and facts
- **RCS** (Redundant Calculation Steps): Add redundant calculation steps
- **SD** (Semantic Distraction): Add semantic distraction information

Each noisy dataset is generated based on the original Clean dataset.

## ğŸ¤– Model Description

### DiffLlama-375M

- **Type**: Llama variant based on differential attention mechanism
- **Parameters**: 375M
- **Features**: Specialized differential attention mechanism

### Llama-375M

- **Type**: Standard Llama architecture
- **Parameters**: 375M
- **Features**: Traditional attention mechanism

## ğŸ“ˆ Result Analysis

### Output Files

```bash
results/
â”œâ”€â”€ experiment_report_[timestamp].csv      # Main performance results
â”œâ”€â”€ detailed_results_[timestamp].json      # Detailed results
â”œâ”€â”€ attention_analysis_sft.json            # Attention analysis
â”œâ”€â”€ sft_performance.csv                    # Performance comparison
â””â”€â”€ attention_maps/                        # Attention heatmaps
    â”œâ”€â”€ clean_q1_sft/
    â”œâ”€â”€ ......
    â”œâ”€â”€ INF_noise_q1_sft/
    â”œâ”€â”€ ......
    â”œâ”€â”€ RCS_noise_q1_sft/
    â”œâ”€â”€ ......
    â”œâ”€â”€ SD_noise_q1_sft/
    â””â”€â”€ ......
```

### Performance Metrics

#### Pass@1 Accuracy

- The proportion of models that give the correct answer on their first attempt
- Main evaluation metric

#### Attention Analysis Metrics

- **KMI Ratio**: Proportion of attention focused on key mathematical information
- **NI Ratio**: Proportion of attention focused on noise information
- **OC Ratio**: Proportion of attention focused on other content

## ğŸ“„ License

This project is licensed under the MIT License. See the LICENSE file for details.
